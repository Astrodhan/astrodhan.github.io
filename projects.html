<!DOCTYPE html>
<html>
<head>
    <title>Projects</title>
    <meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./styles.css">
</head>
<body>
<table style="width: 75%;">
    <tr>
        <td>
            <b><h1>Projects</h1></b>
        </td>
    </tr>
</table>
<table style="width: 75%;">
    <tr>
        <td>
            <table class="intable">
                <tr>
                    <td>
                        <b><h2>Projects I am currently undertaking</h2></b>
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><h3>Photobremic integrator</h3></b>
                        Accounting for light-lag (photobremia) in gravitational trajectories, usually computed with RK4. 
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><h3>Trinary systems' lightcurve simulator</h3></b>
                        Simulating the lightcurves created by a general 3-star system. I did a lot of work on this at IUCAA, taking it further now.
                    </td>
                </tr>
               <tr>
                    <td>
                        <b><h3>Corrections for apsidal precession</h3></b>
                        Many computations and analyses in astrophysics today do not take relativistic apsidal precession into account, I am correcting them. This analysis will open the door to extracting more information out of the present data.
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><h3>Android apps:</h3></b>
                        For the first project I am making a simple app which translates a word in a PDF when long pressed, good for reading books in a language you are not yet fluent in.<br>
			I have also started work on the stellarium for the blind project, which is also going to be an android app.
                    </td>
                </tr>
               
            </table>
        </td>
        <td>
            <table class="intable">
                <tr>
                    <td><b><h2>Projects in development/sitting still:</h2></b></td>
                </tr>
                <tr>
                    <td>
                        <b><h3>Glasses with adjustable shade</h3></b>
                        These glasses can be used indoors as normal reading glasses. When it is sunny outdoors, you can change their shade as you need; and when you wish to look at an eclipse, you can rotate the rotor all the way to "eclipse" mode. There is also a possibility of changing the tint of the glasses between None, Cyan and Magenta.<br>
                        <b>Update:</b> A prototype is made. Below is the proof of concept.
                        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/L7jXTHm04ww?si=OW4hEgsbxPEft-O2" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><h3>Automated audio-video editing from raw files</h3></b>
                        Using python libraries for movie editing, audio and video processing I am making a program that produces a finished video. This project is aimed at a specific application, particularly for editing lectures shot from two cameras and four microphones.
                        GitHub link: <a href="https://github.com/Astrodhan/film_bot">Click here.</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><h3>Wearable navigator for presentations</h3></b>
                        This glove lets you navigate a slide show in a presentation without having to carry a mouse or a clicker. All you need to do is touch your index finger and thumb. Flexing your middle finger gives you right click. Next versions will be better (a little funding would help).<br>
                        <iframe width="260" height="515" src="https://www.youtube-nocookie.com/embed/xlNT4dLU6CA?si=OlK6H0YdW3rOF58e" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                    </td>
                </tr>
            </table>
        </td>
    </tr>
    <tr>
        <td>
            <b><h2>Prospective projects (which you could join/fund):</h2></b>
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>LangYaar: AI friend in your ear who helps you learn/master a new language.</h3></b>
            An LLM based AI tool which which will help you finish your sentences and correct your grammar while you are speaking. It will also help you construct entire new sentences based on the conversation you are having.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Automated CNN based lightcurve classifier</h3></b>
            Lightcurves still need to be classified into Cepheids, RR Lyra, Binary stars, Exoplanets etc; which should be done by machines now (with good accuracy, of course). I am using the Kepler data.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Robotised clothes-making</h3></b>
            Imagine if you walked into a shop, typed in your measurements, selected the fabric, style, embroidery etc; waited for a while and walked out with custom made clothes that fit you perfectly made completely by robots!
            We don't even need AI for this, just need to invent a machine.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Physics embedded digital white-board</h3></b>
            A physics teacher would draw a physics problem on the digital white-board and be able to execute a real-time physics simulation as it is in the problem. For example, she can set the values of gravitational acceleration and air-drag etc and launch a projectile which shall land at the appropriate spot, hopefully calculated by the students.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Accurate real time astronomical green laser pointer/ Pocket Planetarium </h3></b>
            If you don't have a motorised telescope, and you hate calibrating your finderscope; you can simply tell this raspberry pi enabled robotic laser pointer to point to the Andromeda galaxy (or any object or coordinates of interest); which you shall quickly find using your normal telescope.<br>
            This product can be made more commercial with the possibility of making it a 'pocket-planetarium'. Campers can take this small device to dark areas, press a button and then the device will point a laser to all the important objects from that night and talk to them about it poetically.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Graph based digital file format</h3></b>
            Can't write in a linear fashion? Want to write stories which can take a tangent at any point and that gets discussed? Do you wish to write research articles but don't want to explain every little thing? Let the reader choose to navigate the page as they please.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Stellarium for the blind</h3></b>
            While talking to a blind friend of mine, I realised he had never seen stars. Stellarium mobile has a gyroscope which it uses for its demi-AR feature. What we need to do is vibrate the phone (haptic feedback is better than acoustic, as per the blind people I spoke with) when there is a prominent star in the center, modulated with its intensity. If we are using audio then we can use frequency to indicate colour and amplitude to indicate brightness of a star. We can add many other features. People using this app will get a 3D-oriented feel of the cosmos that we can't even fathom; for us sighted people, stars disappear when they set beneath the horizon.<br> <b>Started working on this</b>
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Transliteration between indic texts</h3></b>
            I wanted to read the lyrics to a song in Bangla (Bengali) but since the Latin script has far fewer letters and sounds, I realised I can't know the actual pronunciations by reading the lyrics in the Latin script. However, most indo-Aryan languages and Dravidi languages except Tamil have very similar abugidas derived from the Sanskrut system. So we would be able to write a transliteration tool which transliterates between these languages easily. Note that we are talking about converting between scripts only, not talking about translation. We will learn a lot about unicode we will also learn all the major scripts in India.<br> <b> Edit: ChatGPT can do it now, there is a library being developed named 'indic-transliteration' in python.</b>
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Lingua Cosmica and Deep Learning</h3></b>
            Lingua Cosmica or Lincos is a language constructed by a mathematician named Hans Freudenthal in the 60s. As the name suggests, it is intended to be used as a communication medium between alien species, particularly between humans and any extra-terrestrial intelligence we may encounter. Of course, such a task is very difficult. Prof. Freudenthal has based this language in mathematical and logical principles which we may assume to share with the aliens.<br>
            There are many possibilities here, one is creating a translation tool; from natural language like English to lincos.<br>
            More importantly, we can use AI to create an advanced language. We may treat the AI as the alien and send the language in its intended order and test if the AI is able to understand it. At the moment I am not sure whether such a task would require Artificial General Intelligence or we may be able to program GPT-4 etc to guess what we are talking about.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>AI mental health classifier over scribbles</h3></b>
            Visual tests such as Rorschach inkblot test, 'draw a person' etc need to be taken at face value and often rely on the expertise of the medical practioniner. It is entirely possible to create a new test and train a supervised classifier to classify people. We can start with schizophrenia, however we must be very careful while making a neural network diagnostic tool, especially since we cannot explain the weights and the biases. The goal is to see if people with schizophrenia draw scribbles differently, and differently enough for early diagnosis and care.
        </td>
    </tr>
    <tr>
        <td>
            <b><h3>Interactive digital research papers</h3></b>
            <b>Update: It has been done, Pluto.jl for the win!</b><br>
            Most people read PDFs of research papers these days and journals are all online. So we can create digital versions of the research papers which are a lot more interactive. For example, in this research paper, the reader will be able to alter the plots, download the data directly, even make their own plots in the webpage itself. We can put 3D objects or scenes in the paper instead of putting many cross sections and views.<br>
            We would need to write a markup language built on LaTeX so that anyone could write a paper like this, and it should also be available as a PDF for the old-timers. We can use Julia for the interactive web-plotting and display.
        </td>
    </tr>
</table>
</body>
</html>


